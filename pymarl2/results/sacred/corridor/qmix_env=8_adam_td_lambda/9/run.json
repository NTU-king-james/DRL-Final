{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src",
    "dependencies": [
      "munch==2.5.0",
      "numpy==1.24.4",
      "PyYAML==5.3.1",
      "sacred==0.7.5",
      "torch==2.4.1"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [],
    "sources": [
      [
        "main.py",
        "_sources/main_b3ff5451593b67cd33b9ec035b3b4842.py"
      ],
      [
        "utils/logging.py",
        "_sources/logging_ce9a261c391cbeae67129d3d806d06da.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/llm/test_llm.py\", line 79, in _get_actions_from_llm_api\n    response = openai.ChatCompletion.create(\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n    return super().create(*args, **kwargs)\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n    response, _, api_key = requestor.request(\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/openai/api_requestor.py\", line 288, in request\n    result = self.request_raw(\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/openai/api_requestor.py\", line 596, in request_raw\n    result = _thread_context.session.request(\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 536, in _make_request\n    response = conn.getresponse()\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/urllib3/connection.py\", line 507, in getresponse\n    httplib_response = super().getresponse()\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/http/client.py\", line 1348, in getresponse\n    response.begin()\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/http/client.py\", line 316, in begin\n    version, status, reason = self._read_status()\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/http/client.py\", line 277, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/socket.py\", line 681, in readinto\n    return self._sock.recv_into(b)\n",
    "KeyboardInterrupt\n",
    "\nDuring handling of the above exception, another exception occurred:\n\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/kingjames/miniconda3/envs/pymarl2/lib/python3.8/site-packages/sacred/config/captured_function.py\", line 48, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"src/main.py\", line 38, in my_main\n    run_REGISTRY[_config['run']](_run, config, _log)\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/run/run.py\", line 54, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/run/run.py\", line 178, in run_sequential\n    episode_batch = runner.run(test_mode=False)\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/runners/episode_runner.py\", line 71, in run\n    reward, terminated, env_info = self.env.step(actions[0])\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/envs/starcraft/StarCraft2Env.py\", line 436, in step\n    llm_instruction = self.llm_agent.act(global_state_nl, avail_actions_list, n_agents, env_info)\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/llm/test_llm.py\", line 104, in act\n    chosen_actions = list(self._get_actions_from_llm_api(prompt, n_agents, all_agent_available_action_indices, n_total_actions))\n",
    "  File \"/Users/kingjames/Desktop/\u56db\u4e0a/DRL-Final/pymarl2/src/llm/test_llm.py\", line 92, in _get_actions_from_llm_api\n    print(\"Parse action error!\\nLLM output:\",llm_output_str)\n",
    "UnboundLocalError: local variable 'llm_output_str' referenced before assignment\n"
  ],
  "heartbeat": "2025-05-26T09:03:43.439444",
  "host": {
    "ENV": {},
    "cpu": "Apple M2",
    "hostname": "chenxindeMacBook-Air.local",
    "os": [
      "Darwin",
      "macOS-15.0-arm64-arm-64bit"
    ],
    "python_version": "3.8.20"
  },
  "meta": {
    "command": "my_main",
    "options": {
      "--beat_interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print_config": false,
      "--priority": null,
      "--queue": false,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "env_args.map_name=corridor",
        "runner=episode",
        "batch_size_run=1"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2025-05-26T08:53:43.532118",
  "status": "FAILED",
  "stop_time": "2025-05-26T09:03:43.440804"
}